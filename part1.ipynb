{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "part1",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1QgDd0cmNlE"
      },
      "source": [
        "!sudo apt-get update >& /dev/null\n",
        "!apt-get install -y xvfb x11-utils >& /dev/null\n",
        "!pip install gym==0.17.* pyvirtualdisplay==0.2.* PyOpenGL==3.1.* PyOpenGL-accelerate==3.1.* >& /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeqvP0g0W7i2"
      },
      "source": [
        "n_states = 36\n",
        "iter_max = 10000\n",
        "initial_lr = 1.0\n",
        "min_lr = 0.003\n",
        "gamma = 1\n",
        "eps_max = 10000\n",
        "eps = 0.02"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6z8uTICXKTS"
      },
      "source": [
        "def exec_episodes(env, policy=None, render=False):\n",
        "  obs = env.reset()\n",
        "  total_reward = 0\n",
        "  step_idx = 0\n",
        "  for _ in range(eps_max):\n",
        "    if render:\n",
        "      env.render()\n",
        "    if policy is None:\n",
        "      action = env.action_space.sample()\n",
        "    else:\n",
        "      pos, vel = get_state_vals(env, obs)\n",
        "      action = policy[pos][vel]\n",
        "    obs, reward, done, _ = env.step(action)\n",
        "    total_reward += gamma ** step_idx*reward\n",
        "    step_idx += 1\n",
        "    if done:\n",
        "      break\n",
        "  return total_reward"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BWfBklldpnL"
      },
      "source": [
        "!mkdir ./video"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeChYpYda_eW"
      },
      "source": [
        "import glob\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "from pyvirtualdisplay import Display\n",
        "\n",
        "display = Display(visible=0, size=(1368, 768))\n",
        "display.start()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7aRITfekp7D"
      },
      "source": [
        "def show_video():\n",
        "  mp4list = glob.glob('video/*.mp4')\n",
        "  if len(mp4list) > 0:\n",
        "    mp4 = mp4list[0]\n",
        "    video = io.open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay loop controls style=\"height: 256px;\"> <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" /></video>'''.format(encoded.decode('ascii'))))\n",
        "  else:\n",
        "    print(\"Could not find video\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbfuME4nYJ_r"
      },
      "source": [
        "import gym\n",
        "from gym.wrappers import Monitor\n",
        "\n",
        "def wrap_env(env):\n",
        "  ''''\n",
        "  This monitoring wrapper records the outputs and save them in an mp4 file\n",
        "  '''\n",
        "  env = Monitor(env, './video', force=True)\n",
        "  return env\n",
        "\n",
        "env = wrap_env(gym.make('MountainCar-v0'))\n",
        "env.seed(16)\n",
        "\n",
        "print('Action space for Mountain car env: '+str(env.action_space))\n",
        "print('Observation space for Mountain car env: '+str(env.observation_space))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgCeUU0kehzb"
      },
      "source": [
        "def get_state_vals( env, obs):\n",
        "  env_low = env.observation_space.low\n",
        "  env_high = env.observation_space.high\n",
        "  env_dx = (env_high - env_low)/n_states\n",
        "  pos = int((obs[0] - env_low[0])/env_dx[0])\n",
        "  vel = int((obs[1] - env_low[1])/env_dx[1])\n",
        "  return pos, vel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvhS_cZIfMR0"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "q_table = np.zeros((n_states, n_states, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fKXmTCUlzu-"
      },
      "source": [
        "def eval_policy(env):\n",
        "  solution_policy = np.argmax(q_table, axis=2)\n",
        "  scores = [exec_episodes(env, solution_policy, False) for _ in range(100)]\n",
        "  return np.mean(scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8O6KaEOfuXo"
      },
      "source": [
        "for i in range(iter_max):\n",
        "  obs = env.reset()\n",
        "  eta = max(min_lr, initial_lr*(0.85**(i//100)))\n",
        "  for j in range(eps_max):\n",
        "    pos, vel = get_state_vals(env, obs)\n",
        "    if np.random.uniform(0, 1) < 0.02:\n",
        "      action = np.random.choice(env.action_space.n)\n",
        "    else:\n",
        "      logits = q_table[pos][vel]\n",
        "      logits_exp = np.exp(logits)\n",
        "      probs = logits_exp / np.sum(logits_exp)\n",
        "      action = np.random.choice(env.action_space.n, p=probs)\n",
        "    obs, reward, done, _ = env.step(action)\n",
        "\n",
        "    pos_, vel_ = get_state_vals(env, obs)\n",
        "    q_table[pos][vel][action] = q_table[pos][vel][action] +\\\n",
        "      eta * (reward+gamma*np.max(q_table[pos_][vel_])-q_table[pos][vel][action])\n",
        "    if done:\n",
        "      break\n",
        "  if i % 1000 == 0:\n",
        "    print('Iteration: %d has been completed.'%(i+1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBl59YIzkQi3"
      },
      "source": [
        "show_video()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vesf06TgkaCe"
      },
      "source": [
        "eval_policy(env)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgIfHfCumIfK"
      },
      "source": [
        "!zip -r /content/file.zip /content/video/\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"/content/file.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}